{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d183f80",
   "metadata": {},
   "source": [
    "# 系統維護工具\n",
    "\n",
    "V0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc17ce",
   "metadata": {},
   "source": [
    "# Init All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c367de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the PostgreSQL database...\n",
      "sys 的 sheets:\n",
      " dict_keys(['description', 'table_def', 's_table_desc', 's_syspar', 's_info_line', 's_info_area', 's_timeseq_rpt', 's_repeat_job', 's_topology_kind', 's_gis_layer', 's_info_point', 's_topology_transfer', 's_topology_node', 's_topology_edge', 's_village_waterin', 's_waterin_qty', 's_waterwork_qty', 's_waterin_quality']) \n",
      "basic 的 sheets:\n",
      " dict_keys(['table_def', 'b_表單說明', 'b_colmeta', 'b_水資源分區', 'b_水資源局', 'b_河川局', 'b_流域', 'b_河川', 'b_排水', 'b_水庫', 'b_水質水量保護區', 'b_水庫集水範圍', 'b_水庫集水區敏感區', 'b_堤防', 'b_排水設施', 'b_水門', 'b_抽水站', 'b_河川斷面樁', 'b_雨量站', 'b_河川水位站', 'b_浮標站', 'b_潮位站', 'b_地下水分區', 'b_地下水觀測井']) \n",
      "rain-station: output/rain-station.csv saved, shape = (2149, 6)\n",
      "reservoir-info: output/reservoir-info.csv saved, shape = (152, 22)\n",
      "waterLevel-station: output/waterLevel-station.csv saved, shape = (5176, 13)\n",
      "waterLevelDrain-station: output/waterLevelDrain-station.csv saved, shape = (1189, 4)\n",
      "waterLevelAgri-station: output/waterLevelAgri-station.csv saved, shape = (359, 4)\n",
      "sewer-station: output/sewer-station.csv saved, shape = (310, 8)\n",
      "tide-station: output/tide-station.csv saved, shape = (86, 4)\n",
      "pump-station: output/pump-station.csv saved, shape = (174, 8)\n",
      "reservoir-info: output/reservoir-info.csv saved, shape = (152, 22)\n",
      "flood-station: output/flood-station.csv saved, shape = (2646, 4)\n",
      "riverlog 的 sheets:\n",
      " dict_keys(['r_rain_station', 'r_reservoir_info', 'r_waterlevel_station', 'r_waterleveldrain_station', 'r_waterlevelagri_station', 'r_sewer_station', 'r_tide_station', 'r_pump_station', 'r_flood_station']) \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from codes.db import * \n",
    "from codes.lib import *\n",
    "from codes.riverlog_for_gis import *\n",
    "import pandasql as ps\n",
    "import os\n",
    "\n",
    "gd={}\n",
    "conn=connect_db()\n",
    "if 1:\n",
    "    load_ods(gd)\n",
    "    riverlog_info_setup(gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce2463",
   "metadata": {},
   "source": [
    "# 維護\n",
    "\n",
    "將以下的 ods 灌入 DB\n",
    "\n",
    "sys.ods, basic.ods, riverlog 基本資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ce8f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_list = ['s_syspar', 's_table_desc', 's_info_point', 's_info_line', 's_info_area', 's_timeseq_rpt', 's_repeat_job', 's_topology_kind', 's_topology_transfer', 's_topology_node', 's_topology_edge', 's_village_waterin', 's_waterin_qty', 's_waterwork_qty', 's_waterin_quality']\n",
      "table:s_table_desc PASS\n",
      "table:s_syspar PASS\n",
      "table:s_info_line PASS\n",
      "table:s_info_area PASS\n",
      "table:s_timeseq_rpt PASS\n",
      "table:s_repeat_job PASS\n",
      "table:s_topology_kind PASS\n",
      "table:s_info_point PASS\n",
      "table:s_topology_transfer PASS\n",
      "table:s_topology_node PASS\n",
      "table:s_topology_edge PASS\n",
      "executing : head -n 1000 output/s_village_waterin.csv | /Volumes/F2020/opt/anaconda3/envs/py37/bin/csvsql -i postgresql --no-constraints --tables 's_village_waterin' >> output/tb.sql\n",
      "executing : head -n 1000 output/s_waterin_qty.csv | /Volumes/F2020/opt/anaconda3/envs/py37/bin/csvsql -i postgresql --no-constraints --tables 's_waterin_qty' >> output/tb.sql\n",
      "executing : head -n 1000 output/s_waterwork_qty.csv | /Volumes/F2020/opt/anaconda3/envs/py37/bin/csvsql -i postgresql --no-constraints --tables 's_waterwork_qty' >> output/tb.sql\n",
      "executing : head -n 1000 output/s_waterin_quality.csv | /Volumes/F2020/opt/anaconda3/envs/py37/bin/csvsql -i postgresql --no-constraints --tables 's_waterin_quality' >> output/tb.sql\n",
      "Connected to the PostgreSQL database...\n",
      "sql_drop script:\n",
      "DROP TABLE IF EXISTS s_village_waterin;\n",
      "DROP TABLE IF EXISTS s_waterin_qty;\n",
      "DROP TABLE IF EXISTS s_waterwork_qty;\n",
      "DROP TABLE IF EXISTS s_waterin_quality;\n",
      "\n",
      "sql script:\n",
      "CREATE TABLE s_village_waterin (\n",
      "\t\"VILLCODE\" VARCHAR, \n",
      "\t\"COUNTYNAME\" VARCHAR, \n",
      "\t\"TOWNNAME\" VARCHAR, \n",
      "\t\"VILLNAME\" VARCHAR, \n",
      "\t\"VILLENG\" VARCHAR, \n",
      "\t\"COUNTYID\" VARCHAR, \n",
      "\t\"COUNTYCODE\" DECIMAL, \n",
      "\t\"TOWNID\" VARCHAR, \n",
      "\t\"TOWNCODE\" DECIMAL, \n",
      "\t\"NOTE\" VARCHAR, \n",
      "\t\"WATERWORK\" VARCHAR, \n",
      "\t\"WATERIN\" VARCHAR\n",
      ");\n",
      "CREATE TABLE s_waterin_qty (\n",
      "\twaterin VARCHAR, \n",
      "\tdate VARCHAR, \n",
      "\tqty DECIMAL\n",
      ");\n",
      "CREATE TABLE s_waterwork_qty (\n",
      "\twaterwork VARCHAR, \n",
      "\tdate DECIMAL, \n",
      "\tqty DECIMAL\n",
      ");\n",
      "CREATE TABLE s_waterin_quality (\n",
      "\tdate DATE, \n",
      "\twaterwork VARCHAR, \n",
      "\titem VARCHAR, \n",
      "\tvalue VARCHAR, \n",
      "\t\"limit\" VARCHAR\n",
      ");\n",
      "\n",
      "psql script:\n",
      "\\copy \"s_village_waterin\" FROM 'output/s_village_waterin.csv' WITH (FORMAT csv,HEADER);\n",
      "\\copy \"s_waterin_qty\" FROM 'output/s_waterin_qty.csv' WITH (FORMAT csv,HEADER);\n",
      "\\copy \"s_waterwork_qty\" FROM 'output/s_waterwork_qty.csv' WITH (FORMAT csv,HEADER);\n",
      "\\copy \"s_waterin_quality\" FROM 'output/s_waterin_quality.csv' WITH (FORMAT csv,HEADER);\n",
      "\n",
      "executing : /Applications/Postgres.app/Contents/Versions/13/bin/psql -h localhost -p 5431 -U postgres postgis -f output/tb.psql -a\n",
      "b'\\\\copy \"s_village_waterin\" FROM \\'output/s_village_waterin.csv\\' WITH (FORMAT csv,HEADER);\\n'\n",
      "b'COPY 179\\n'\n",
      "b'\\\\copy \"s_waterin_qty\" FROM \\'output/s_waterin_qty.csv\\' WITH (FORMAT csv,HEADER);\\n'\n",
      "b'COPY 61\\n'\n",
      "b'\\\\copy \"s_waterwork_qty\" FROM \\'output/s_waterwork_qty.csv\\' WITH (FORMAT csv,HEADER);\\n'\n",
      "b'COPY 61\\n'\n",
      "b'\\\\copy \"s_waterin_quality\" FROM \\'output/s_waterin_quality.csv\\' WITH (FORMAT csv,HEADER);\\n'\n",
      "b'COPY 22\\n'\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "def exec_print(cmd_str):\n",
    "    print(\"executing : %s\" %(cmd_str)) \n",
    "    p = subprocess.Popen(cmd_str, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    for line in p.stdout.readlines():\n",
    "        print(line)\n",
    "    retval = p.wait()    \n",
    "    \n",
    "\n",
    "def ods_to_scr(tables,sql_name,psql_name,sql_drop_name, white_list=None):\n",
    "    \"\"\"\n",
    "    white_list: 如果有，就只處理這些表\n",
    "    \"\"\"\n",
    "    loc=\"/Volumes/F2020/opt/anaconda3/envs/py37/bin/csvsql\"\n",
    "    sqls=[]\n",
    "    sqls_drop=[]\n",
    "    table_list=[]\n",
    "    if 'table_def' in tables:\n",
    "        def_df=tables['table_def']\n",
    "        table_list = def_df[def_df['type']=='T']['table_name'].to_list()\n",
    "        print(\"table_list = %s\" %(table_list))\n",
    "    for t_name in tables:\n",
    "        if (not t_name=='table_def') and t_name in table_list:\n",
    "            if white_list and not (t_name in white_list):\n",
    "                print(\"table:%s PASS\" %(t_name))\n",
    "                pass\n",
    "            else:\n",
    "                df = tables[t_name]\n",
    "                sqls_drop.append(\"DROP TABLE IF EXISTS %s;\" %(t_name))\n",
    "\n",
    "                filename = \"output/%s.csv\" %(t_name)\n",
    "                df.to_csv(filename,index=False)\n",
    "                cmd_str=\"head -n 1000 output/%s.csv | %s -i postgresql --no-constraints --tables '%s' >> %s\" %(t_name,loc,t_name,sql_name)\n",
    "                exec_print(cmd_str)\n",
    "                psql=\"\\\\copy \\\"%s\\\" FROM 'output/%s.csv' WITH (FORMAT csv,HEADER);\" %(t_name,t_name)\n",
    "                sqls.append(psql)\n",
    "    \n",
    "    with open(psql_name, 'a') as f:\n",
    "        for line in sqls:\n",
    "            f.write(\"%s\\n\" %(line))\n",
    "\n",
    "    with open(sql_drop_name, 'a') as f:\n",
    "        for line in sqls_drop:\n",
    "            f.write(\"%s\\n\" %(line))\n",
    "\n",
    "sql_drop_name=\"output/tb_drop.sql\"\n",
    "sql_name = \"output/tb.sql\"\n",
    "psql_name = \"output/tb.psql\"\n",
    "\n",
    "#產生 sql, psql\n",
    "if 0:\n",
    "    if os.path.exists(sql_drop_name):\n",
    "        os.remove(sql_drop_name)\n",
    "    if os.path.exists(sql_name):\n",
    "        os.remove(sql_name)\n",
    "    if os.path.exists(psql_name):\n",
    "        os.remove(psql_name)\n",
    "\n",
    "    ods_to_scr(gd['sys'],sql_name,psql_name,sql_drop_name,['s_village_waterin','s_waterin_qty','s_waterwork_qty','s_waterin_quality'])\n",
    "    #ods_to_scr(gd['basic'],sql_name,psql_name,sql_drop_name)\n",
    "    #ods_to_scr(gd['riverlog'],sql_name,psql_name,sql_drop_name)\n",
    "\n",
    "#manual modify schema\n",
    "# r_waterlevel_station,b_河川水位站\n",
    "    \n",
    "#drop, create table\n",
    "if 0:\n",
    "    conn=connect_db()\n",
    "    with open (sql_drop_name, \"r\") as scrfile:\n",
    "        sqls=scrfile.readlines()\n",
    "\n",
    "    sql_str = \"\".join(sqls)\n",
    "    print(\"sql_drop script:\\n%s\" % (sql_str))\n",
    "    sql_exec(conn,sql_str)\n",
    "    \n",
    "    with open (sql_name, \"r\") as scrfile:\n",
    "        sqls=scrfile.readlines()\n",
    "\n",
    "    sql_str = \"\".join(sqls)\n",
    "    print(\"sql script:\\n%s\" % (sql_str))\n",
    "    sql_exec(conn,sql_str)\n",
    "\n",
    "#import data\n",
    "if 0:\n",
    "    psql=\"/Applications/Postgres.app/Contents/Versions/13/bin/psql\"\n",
    "    with open (psql_name, \"r\") as sqlfile:\n",
    "        sqls=sqlfile.readlines()\n",
    "    psql_str = \"\".join(sqls)\n",
    "    print(\"psql script:\\n%s\" %(psql_str))\n",
    "\n",
    "    cmd_str=\"%s -h localhost -p 5431 -U postgres postgis -f %s -a\" %(psql,psql_name)\n",
    "    exec_print(cmd_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e0886",
   "metadata": {},
   "source": [
    "# 使用範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gd['base']['拓墣-Node']\n",
    "#gd['riverlog'][\"r_rain_station\"]\n",
    "if 0:\n",
    "    df = gd['basic']['河川局']\n",
    "    #query_str = \"\"\"SELECT * FROM df_8410 where site_id like '%東區%'\"\"\"\n",
    "    query_str = \"\"\"SELECT * FROM df where rvb_name='第一河川局'\"\"\"\n",
    "    q1_df= ps.sqldf(query_str, locals())\n",
    "#q1_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11824833",
   "metadata": {},
   "source": [
    "# DB 存取範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e7975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "conn=connect_db()\n",
    "\n",
    "if 0:\n",
    "    sql = \"select * from rivercode order by river_id\"\n",
    "    df = sql_to_df(conn,sql)\n",
    "\n",
    "if 0:\n",
    "    df = gd['basic']['河川局']\n",
    "    df.to_csv('output/河川局.csv')    \n",
    "\n",
    "if 1:\n",
    "    sql=\"\"\"\n",
    "    CREATE TABLE \"河川局\" (\n",
    "        a DECIMAL, \n",
    "        rvb_no DECIMAL, \n",
    "        rvb_name VARCHAR, \n",
    "        area BOOLEAN, \n",
    "        \"水資源分區代號\" BOOLEAN\n",
    "    );\n",
    "\n",
    "    \"\"\"\n",
    "    sql_exec(conn,sql)\n",
    "if 0:\n",
    "    sql = 'select * from 河川局'\n",
    "    df = sql_to_df(conn,sql)\n",
    "if 1:\n",
    "    close_db(conn)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d36b9b0",
   "metadata": {},
   "source": [
    "# shp 匯入資料庫\n",
    "\n",
    "用 data 目錄下的 shp 產生 script, 再手動到命令列執行，灌入資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ed55c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shp2pgsql -W UTF-8 -D -s 102443 -I \"./data/8818-工業區污水處理廠分布位置圖/工業區污水處理廠分布_121.shp\" \"8818-工業區污水處理廠分布位置圖\">> data/shp.sql\n",
      "psql -p 5431 -U postgres -d postgis -f data/shp.sql\n"
     ]
    }
   ],
   "source": [
    "pathnames_ori = walk_dir(\"./data\",\".shp\",['工業區污水處理廠分布_121.shp']) #\n",
    "pathnames = list_remove(pathnames_ori,['_Sanhe'])\n",
    "#print(pathnames)\n",
    "shp_tosql(pathnames,\"8818-工業區污水處理廠分布位置圖\",\"data/shp.sql\",102443,\"UTF-8\")\n",
    "#shp_tosql(lines,,table_name, sql_path=\"data/shp.sql\", srid=3826, encoding=\"UTF-8\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a40e7",
   "metadata": {},
   "source": [
    "# 讀取單月淨水場水質資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename=\"/Volumes/F2020/MakerBk2/QGIS/projects/hackathon/自來水水質資訊_202105.csv\"\n",
    "\n",
    "mv_str=\"。\"\n",
    "df_csv = pd.read_csv(filename,header=[0,1,2,3])\n",
    "\n",
    "if True:\n",
    "    values = []\n",
    "    for index, row in df_csv.iterrows():\n",
    "        line = str(row['淨水場資訊'][0])\n",
    "        cols = line.split(\"(\")\n",
    "        print(cols[0].strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb871b4a",
   "metadata": {},
   "source": [
    "# 單月淨水場水質 CSV 分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c27988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總溶解固體量(Total Dissolved Solids)-單位:mg/L, 飲用水水質標準:500\n",
      "尖石淨水場:84.8\n",
      "梅花淨水場:123.0\n",
      "內灣淨水場:167.0\n",
      "桃山淨水場:170.0\n",
      "東興淨水場:187.0\n",
      "芎林淨水場:237.0\n",
      "新竹第二淨水場:242.0\n",
      "寶山淨水場:246.0\n",
      "員崠淨水場:253.0\n",
      "新竹第一淨水場:263.0\n"
     ]
    }
   ],
   "source": [
    "#列出頭前溪流域淨水場的 總溶解固體量(Total Dissolved Solids)\n",
    "import pandas as pd\n",
    "filename=\"/Volumes/F2020/MakerBk2/QGIS/projects/hackathon/自來水水質資訊_202105.csv\"\n",
    "#targets=[\"第一淨水場\",\"第二淨水場\",\"東興淨水場\",\"寶山淨水廠\",\"員崠淨水場\",\"梅花淨水場\",\"尖石淨水場\",\"內灣淨水場\",\"桃山淨水場\",\"芎林淨水場\"]\n",
    "targets=['新竹第一淨水場','新竹第二淨水場','東興淨水場','寶山淨水場','員崠淨水場','梅花淨水場','尖石淨水場','內灣淨水場','桃山淨水場','芎林淨水場']\n",
    "df_csv = pd.read_csv(filename,header=[0,1,2,3])\n",
    "item_name='總溶解固體量(Total Dissolved Solids)'\n",
    "\n",
    "if True:\n",
    "    idvalue = {}\n",
    "    for col_info in df_csv.columns:\n",
    "        if col_info[0]==item_name:\n",
    "            #print(col_info)\n",
    "            info_str=\"%s-單位:%s, 飲用水水質標準:%s\" %(col_info[0],col_info[3],col_info[2])\n",
    "            print(info_str)\n",
    "            break\n",
    "    for index, row in df_csv.iterrows():\n",
    "        factory=row['淨水場名稱'][0]\n",
    "        if factory in targets:\n",
    "            value = row[item_name][0]            \n",
    "            #print(\"%s:%s\" %(factory,value))\n",
    "            idvalue[factory]=value\n",
    "    \n",
    "    items = sorted(idvalue.items(), key=lambda x:x[1])\n",
    "    for item in items:\n",
    "        print(\"%s:%s\" %(item[0],item[1]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaaf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 算感測值跟標準的比例\n",
    "df_result['test'] = pd.to_numeric(df_result['飲用水水質標準'])\n",
    "df_result\n",
    "if 0:\n",
    "    f1=df_result['飲用水水質標準'].str.isnumeric()\n",
    "    df3=df_result[f1]\n",
    "    df4=df3['percent']=df3['值']/df3['飲用水水質標準']*100\n",
    "    df4\n",
    "#df_out=df_result['percent']=df_result['值']/df_result['飲用水水質標準']*100\n",
    "#df_out.to_csv('output/water_quality_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22480517",
   "metadata": {},
   "source": [
    "# 淨水場水質資料灌入資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def lines_to_file(lines,filename):\n",
    "    fp = open(filename, \"w\")\n",
    "    fp.write(\"\\n\".join(lines))\n",
    "    fp.close()\n",
    " \n",
    "def update_waterwork_quantity(src_pairs,sql_filename):\n",
    "    \"\"\" 將列的幾個淨水場水質報告檔案，產生灌入資料庫的 sql\n",
    "    每個月的第一筆 sql 是 delete 同資料日期的資料，如果改同月資料日期，記得手動刪除\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    idx_colname=['區處別','系統代號','淨水場名稱','淨水場資訊']\n",
    "    idxs={}\n",
    "    values={}\n",
    "    sqls=[]\n",
    "\n",
    "    for [filename, date_str] in src_pairs:\n",
    "        sql=\"DELETE FROM m_waterwork_quality WHERE \\\"日期\\\" = '%s';\" %(date_str)\n",
    "        sqls.append(sql)\n",
    "        idxs['日期']=date_str\n",
    "        df_csv = pd.read_csv(filename,header=[0,1,2,3])\n",
    "        for index, row in df_csv.iterrows():\n",
    "            cols = row.keys() #('區處別', 'Unnamed: 0_level_1', 'Unnamed: 0_level_2', 'Unnamed: 0_level_3')\n",
    "\n",
    "            for col in cols:\n",
    "                #print(\"%s=%s\" %(col[0],row[col]))\n",
    "\n",
    "                if col[0] in idx_colname:\n",
    "                    idxs[col[0]]=row[col]\n",
    "                else:\n",
    "                    values['項目']=col[0]\n",
    "                    if col[0]=='水質合格否(Y/N)':\n",
    "                        values['值']=row[col]\n",
    "                        values['項次']=0\n",
    "                        values['飲用水水質標準']=\"\"\n",
    "                        values['單位']=\"\"\n",
    "                    else:\n",
    "                        values['值']=row[col]\n",
    "                        values['項次']=col[1]\n",
    "                        values['飲用水水質標準']=col[2]\n",
    "                        values['單位']=col[3]\n",
    "                    #print(\"idxs=%s\\nvalues=%s\" %(idxs,values))\n",
    "\n",
    "\n",
    "                    values_str = \"'%s','%s','%s','%s','%s','%s','%s','%s','%s','%s'\" %(idxs['日期'], idxs['區處別'], idxs['系統代號'],idxs['淨水場名稱'],values['項目'],values['值'],values['單位'],values['飲用水水質標準'],values['項次'],idxs['淨水場資訊'])\n",
    "\n",
    "                    sql=\"\"\"INSERT INTO m_waterwork_quality(\"日期\", \"區處別\",\"系統代號\",\"淨水場名稱\",\"項目\",\"值\",\"單位\",\"飲用水水質標準\",\"項次\",\"淨水場資訊\") VALUES (%s);\"\"\" %(values_str)\n",
    "                    #print(sql)\n",
    "                    sqls.append(sql)\n",
    "    lines_to_file(sqls,sql_filename)\n",
    "    return sqls\n",
    "src_pairs=[[\"data/自來水水質資訊_202104.csv\",'2021-04-08'], \\\n",
    "           [\"data/自來水水質資訊_202105.csv\",'2021-05-24']]\n",
    "sql_filename=\"data/waterwork_quality.sql\"\n",
    "sqls=update_waterwork_quantity(src_pairs,sql_filename)\n",
    "print(\"%s saved\" %(sql_filename))\n",
    "\n",
    "if 1: # update DB\n",
    "    i=0\n",
    "    for sql in sqls:\n",
    "        if i % 100 ==0:\n",
    "            print(\"%i sqls processed!\" %(i))\n",
    "        sql_exec(conn,sql)\n",
    "        i=i+1\n",
    "    print(\"total %i sqls processed!\" %(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c987db",
   "metadata": {},
   "source": [
    "# 環保署 API\n",
    "以下 API 測試過\n",
    "\n",
    "/stat_p_123 重要河川水質概況\n",
    "\n",
    "/wqx_p_01 河川水質監測資料\n",
    "\n",
    "/dws_p_28 每月自來水水質監測資料\n",
    "\n",
    "/wqx_p_12 河川水質季監測資料\n",
    "\n",
    "/ems_s_01 環境保護許可管理系統(暨解除列管)對象基本資料\n",
    "\n",
    "/stat_p_44 垃圾處理場(廠)統計\n",
    "\n",
    "/stat_p_45 垃圾清理量資料\n",
    "\n",
    "/stat_p_87 垃圾處理場(廠)座數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32811582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這裡可以將 API 資料下載下來，轉換成 df\n",
    "api_key=\"your_key\" #請更新成自己環保署API key\n",
    "limit=1000\n",
    "limit_break=0 #>0 can limit total\n",
    "offset=0\n",
    "load_cnt=0\n",
    "renew_url=True\n",
    "    \n",
    "if 0: #/stat_p_123 重要河川水質概況 -> e_river_state_q\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/stat_p_123?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/stat_p_123-%i.json\"\n",
    "    use_label=True\n",
    "    pass\n",
    "if 0: # /wqx_p_01 河川水質監測資料 -> e_river_q\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/wqx_p_01?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/wqx_p_01-%i.json\"\n",
    "    use_label=False\n",
    "if 0: #/dws_p_28 每月自來水水質監測資料 -> e_waterwork_q\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/dws_p_28?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/dws_p_28-%i.json\"\n",
    "    use_label=False\n",
    "if 0: #/wqx_p_12 河川水質季監測資料 #\"total\": 117041 -> e_river_season_q\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/wqx_p_12?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/wqx_p_12-%i.json\"\n",
    "    use_label=False\n",
    "if 0: #/ems_s_01 環境保護許可管理系統(暨解除列管)對象基本資料 = 118447-環境保護許可管理系統(暨解除列管)對象基本資料     \n",
    "    #\"total\": 322225 -> e_factory_base\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/ems_s_01?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/ems_s_01-%i.json\"\n",
    "    use_label=False\n",
    "if 0: #/stat_p_44 垃圾處理場(廠)統計 \"total\": 220  Garbage disposal site, 不進 DB\n",
    "    url_t=\"https://data.epa.gov.tw/api/v1/stat_p_44?api_key=%s\"\n",
    "    url= url_t % (api_key)\n",
    "    renew_url=False\n",
    "    filename_t= \"output/stat_p_44-%i.json\"\n",
    "    use_label=False\n",
    "if 0: #/stat_p_45 垃圾清理量資料 \"total\": 902 -> e_trash_stat_qty\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/stat_p_45?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/stat_p_45-%i.json\"\n",
    "    use_label=False     \n",
    "if 0: # /stat_p_46 垃圾清理回收率指標資料 \"total\": 2194 -> e_trash_recycle\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/stat_p_46?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/stat_p_46-%i.json\"\n",
    "    use_label=False \n",
    "if 1: #/stat_p_87 垃圾處理場(廠)座數 \"total\": 575 -> e_garbage_disposal\n",
    "    url_t = \"https://data.epa.gov.tw/api/v1/stat_p_87?offset=%i&limit=%i&api_key=%s\"\n",
    "    filename_t= \"output/stat_p_87-%i.json\"\n",
    "    use_label=False \n",
    "    \n",
    "    \n",
    "    \n",
    "while True:\n",
    "    if renew_url==True:\n",
    "        url= url_t % (offset,limit,api_key)\n",
    "    filename  = filename_t %(offset)\n",
    "    print(\"url=%s\" %(url))\n",
    "    url_get(filename, url,False)\n",
    "    data = load_json(filename)\n",
    "\n",
    "    if offset==0:\n",
    "        labels={}\n",
    "        d={}\n",
    "        #print(\"labels:\")\n",
    "        for i in range(len(data['fields'])):\n",
    "            #print(\"%s=%s\" %(data['fields'][i]['id'],data['fields'][i]['info']['label']))\n",
    "            labels[data['fields'][i]['id']]=data['fields'][i]['info']['label']\n",
    "        print(\"labels=%s\" %(labels))\n",
    "        print(\"total=%i\" %(data['total']))\n",
    "\n",
    "    #print(\"values:\")\n",
    "    records_cnt = len(data['records'])\n",
    "    for i in range(records_cnt):\n",
    "        record_cur = data['records'][i]\n",
    "        #print(\"%i: %s \" %(i, record_cur))\n",
    "        for key in record_cur.keys():\n",
    "            if use_label:\n",
    "                if not labels[key] in d.keys():\n",
    "                    #print(\"key=%s\" %(key))\n",
    "                    d[labels[key]]=[]\n",
    "                d[labels[key]].append(record_cur[key])\n",
    "            else:\n",
    "                if not key in d.keys():\n",
    "                    #print(\"key=%s\" %(key))\n",
    "                    d[key]=[]\n",
    "                d[key].append(record_cur[key])\n",
    "        load_cnt += 1\n",
    "    #load_cnt += records_cnt\n",
    "    print(\"load_cnt=%i\" %(load_cnt))\n",
    "    if load_cnt >= data['total'] or (limit_break>0 and load_cnt >= limit_break):\n",
    "        break\n",
    "    offset += limit\n",
    "\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "#df_to_db('table_name',df,'replace')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a6633d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL Table e_garbage_disposal has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "#上傳資料庫，並建立資料表\n",
    "#df.dtypes\n",
    "df_to_db('e_garbage_disposal',df,'replace')\n",
    "#df.to_csv(\"output/debug.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420a3ad",
   "metadata": {},
   "source": [
    "# EPA CWMS 水量水質自動監測連線處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed4ae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL Table e_cwms_hsinchu has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "filename=\"/Users/wuulong/Downloads/cwms.xml\"\n",
    "if 0: #新竹縣，正常\n",
    "    url=\"HTTP://hsinchuauto.tk/cwmsopendata/cwms.xml\"\n",
    "    url_get(filename,url,reload=True)\n",
    "    df=xml_to_df(filename)\n",
    "    df_to_db('e_cwms_hsinchu',df)\n",
    "if 0: # 新竹市，網站的 xml 檔案無法存取，無法繼續\n",
    "    url=\"HTTP://cwms.hccepb.gov.tw/cwmsopendata/cwms.xml\"\n",
    "    url_get(filename,url,reload=True)\n",
    "    df=xml_to_df(filename)\n",
    "    df_to_db('e_cwms_hsinchucity',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e1bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete from e_cwms_hsinchu where \"M_DATE\"='1100704'\n"
     ]
    }
   ],
   "source": [
    "#測試\n",
    "mdate=df['M_DATE'].unique()[0]\n",
    "sql=\"delete from e_cwms_hsinchu where \\\"M_DATE\\\"='%s'\" %(mdate)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e52d4b",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
